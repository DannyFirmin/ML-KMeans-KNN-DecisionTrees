{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'> COMP2420/COMP6420 - Introduction to Data Management,<br/> Analysis and Security</h1>\n",
    "\n",
    "<h1 align='center'> Assignment - 2</h1>\n",
    "\n",
    "-----\n",
    "<br/>\n",
    "\n",
    "## Grading\n",
    "\n",
    "|**Maximum Marks**         |  **100**\n",
    "|--------------------------|--------\n",
    "|  **Weight**              |  **20% of the Total Course Grade**\n",
    "|  **Submission deadline** |  **7:00PM, Friday, May 24**\n",
    "|  **Submission mode**     |  **Electronic, Using GitLab <br/> One submission per group**\n",
    "|  **Estimated time**      |  **20 hours**\n",
    "|  **Penalty**             |  **100% after the deadline**\n",
    "  \n",
    "\n",
    "\n",
    "## Submission\n",
    "\n",
    "You need to submit the notebook `Assignment-2.ipynb` and any other additional files that you may have created / hyperlinked in this notebook, as part of your submission by pushing it to your forked GitLab repository. You need to add your group details below. Make sure your group works on and submits only have one fork of the assignment repository. \n",
    "\n",
    "\n",
    "### Note:\n",
    "\n",
    "* It is strongly advised to read the whole assignment before attempting it and have at least a cursory glance at the dataset in order to gauge the requirements and understand what you need to do as a bigger picture.\n",
    "\n",
    "* For answers requiring free form written text, use the designated cells denoted by `YOUR ANSWER HERE` -- double click on the cell to write inside them.\n",
    "\n",
    "* For all coding questions please write your code after the comment `YOUR CODE HERE`.\n",
    "\n",
    "* In the process of testing your code, you can insert more cells or use print statements for debugging, but when submitting your file remember to remove these cells and calls respectively.\n",
    "\n",
    "* You will be marked on **correctness** and **readability** of your code, if your marker can't understand your code your marks may be deducted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">\n",
    "    \n",
    "### Group Number :  2420_A2_Grp12\n",
    "\n",
    "### Student IDs: u6555407, u6588836, u6611178\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING FREQUENTLY USED PYTHON MODULES\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import psycopg2\n",
    "import os\n",
    "plt.style.use('seaborn-notebook')\n",
    "%matplotlib inline\n",
    "\n",
    "# JUST TO MAKE SURE SOME WARNINGS ARE IGNORED \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT ANY OTHER REQUIRED MODULES IN THIS CELL\n",
    "### TODO SECTION A: q4 & SECTION B Q1.1\n",
    "#### We might need actor name and corresponding actor id.\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from itertools import combinations \n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section A - Database Management (15 Marks)\n",
    "\n",
    "You have been given the following database containing 15 tables relating to **DVD Movie Rentals**. The data contained in these tables is as follows -\n",
    "\n",
    "|  **Table**               |  **Data Description**      |\n",
    "|--------------------------|----------------------------|\n",
    "|  actor                   |  actors data including first name and last name     |\n",
    "|  film                    |  films data such as title, release year, length, rating, etc      |\n",
    "|  film_actor              |  stores the relationships between films and actors |\n",
    "|  category                |  stores film’s categories data |\n",
    "|  film_category           |  stores the relationships between films and categories | \n",
    "|  store                   |  store data including manager staff and address |\n",
    "|  inventory               |  stores inventory data |\n",
    "|  rental                  |  stores rental data |\n",
    "|  payment                 |  stores customer's payments |\n",
    "|  staff                   |  stores staff data |\n",
    "|  customer                |  stores customer data |\n",
    "|  address                 |  address data for staff and customers |\n",
    "|  city                    |  stores city data |\n",
    "|  country                 |  stores country data |\n",
    "\n",
    "Visualizing the relations between these tables can be aided by looking at the below **E-R Diagram**.\n",
    "\n",
    "<img src='./dvd_rental_er.png'>\n",
    "\n",
    "Based on your understanding of the relationships between these tables, answer the following questions by writing SQL queries to get the required data rows from the database and display them as a **Pandas dataframe**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### **NOTE**:\n",
    "For the following questions, in the CSIT labs you will be able to connect directly to the database using the below code within the notebook. From outside of the CSIT labs, you will need to perform SQL queries in your terminal by using [partch](https://cs.anu.edu.au/docs/student-computing-environment/linuxlabs/remoteaccess/#connectingtopartch3). Once you have the correct query, you may just fill in the boxes below.\n",
    "\n",
    "**Partch Instructions**\n",
    "1. Connect to partch as per the above hyperlink\n",
    "2. In your terminal, enter `psql` to access the sql database\n",
    "3. Enter `\\c dvdrental` to ensure you are accessing the assignment database (or simply specify dvdrental when connecting to the database server -- `psql dvdrental`).\n",
    "4. (Sanity Check) Enter `SELECT * FROM actor;` . If you receive the first row to be \"Penelope Guiness\", you should be good to go !\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "could not connect to server: No such file or directory\n\tIs the server running locally and accepting\n\tconnections on Unix domain socket \"/var/run/postgresql/.s.PGSQL.5432\"?\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e21c2b700078>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Connect using psycopg2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpsycopg2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/var/run/postgresql\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatabase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"dvdrental\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Activate connection cursor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcurr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/psycopg2/__init__.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0mdsn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dsn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection_factory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconnection_factory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwasync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcursor_factory\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor_factory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcursor_factory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: could not connect to server: No such file or directory\n\tIs the server running locally and accepting\n\tconnections on Unix domain socket \"/var/run/postgresql/.s.PGSQL.5432\"?\n"
     ]
    }
   ],
   "source": [
    "# Connect using psycopg2\n",
    "conn = psycopg2.connect(host=\"/var/run/postgresql\", database=\"dvdrental\")\n",
    "\n",
    "# Activate connection cursor\n",
    "curr = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_sql(query):\n",
    "    # Select table and display\n",
    "    curr.execute(query)\n",
    "\n",
    "    # Fetches all the rows from the result of the query\n",
    "    rows = curr.fetchall()\n",
    "    \n",
    "    # Gets the column names for the table\n",
    "    colnames = [desc[0] for desc in curr.description]\n",
    "\n",
    "    # Converts into readable pandas dataframe\n",
    "    df_result = pd.DataFrame(rows, columns=colnames)\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Write an SQL query to determine the total sales from the rentals of the film 'Affair Prejudice' from the rental store with `store_id = 2`. Your query should result in a single column called `Total Rental Cost` with the value of the total cost of all these rentals.\n",
    "<span style= 'float: right;'><b>[3 marks]</b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR QUERY HERE\n",
    "query = str(\"SELECT SUM(p.amount) AS TOTAL_RENTAL_COST\"\n",
    "            + \" FROM payment AS p,rental AS r,inventory AS i,film AS f\"\n",
    "            + \" WHERE p.rental_id=r.rental_id\"\n",
    "            + \" AND r.inventory_id=i.inventory_id\"\n",
    "            + \" AND i.film_id=f.film_id\"\n",
    "            + \" AND f.title LIKE 'Affair Prejudice'\"\n",
    "            + \" AND i.store_id=2;\")\n",
    "\n",
    "execute_sql(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write an SQL query to retrieve the names of all customers who rented the film ‘Affair Prejudice’ from the store with `store_id = 1`. The result of your query should display each customer's first name and last name. \n",
    "<span style= 'float: right;'><b>[3 marks]</b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR QUERY HERE\n",
    "query = str(\"SELECT c.first_name,c.last_name\"\n",
    "            + \" FROM customer AS c,rental AS r,inventory AS i,film AS f\"\n",
    "            + \" WHERE c.customer_id=r.customer_id\"\n",
    "            + \" AND r.inventory_id=i.inventory_id\"\n",
    "            + \" AND i.film_id=f.film_id\"\n",
    "            + \" AND f.title LIKE '%Affair Prejudice%'\"\n",
    "            + \" AND c.store_id=1;\")\n",
    "\n",
    "execute_sql(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Write an SQL query to retrieve the names of all those customers who have a total of more than 100 dollars in recorded payments. Your query's result should include each customer's first name, last name and customer ID. \n",
    "<span style= 'float: right;'><b>[4 marks]</b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR QUERY HERE\n",
    "query = str(\"SELECT c.first_name,c.last_name,c.customer_id\"\n",
    "            + \" FROM customer AS c, payment AS p\"\n",
    "            + \" WHERE c.customer_id=P.customer_id\"\n",
    "            + \" GROUP BY c.customer_id HAVING SUM(p.amount)>100;\")\n",
    "\n",
    "execute_sql(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Write an SQL query to retrieve the names of all customers who have rented the movie ‘Angels Life’ from *both* stores with `store_id = 1` and `store_id = 2`. Your query's result should include each customer's first name, last name and customer ID.\n",
    "<span style= 'float: right;'><b>[5 marks]</b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR QUERY HERE\n",
    "query = str(\"SELECT c.first_name,c.last_name,c.customer_id\"\n",
    "            + \" FROM customer AS c, payment AS p\"\n",
    "            + \" WHERE c.customer_id=P.customer_id\"\n",
    "            + \" GROUP BY c.customer_id HAVING SUM(p.amount)>100;\")\n",
    "\n",
    "execute_sql(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section B - Data Acquisition (20 Marks)\n",
    "\n",
    "In this section, you need to read and import the data from the database into Python and make it ready to be used by your machine learning algorithms in the next section. **Your task here is to load the required columns from the various appropriate tables in the database to fuel the data required to train your machine learning models in the next section.** You can load the required data into one or more Pandas dataframes, to suit the the needs of different Machine Learning models in Section C. \n",
    "\n",
    "If you fail to do so, or an error in the previous section is preventing you from doing so, we can provide you with a **CSV of the required data**. If you choose to use this CSV, you will not receive any marks for this section, but you'll be able to do the following section without having to spend time on this section.  \n",
    "\n",
    "<span style='color:red;'><b>Note:</b> While you are provided the .csv files to use for development of the later questions at home, you must submit a copy of the code that can read the database to receive marks for this section.</span>\n",
    "<span style= 'float: right;'><b>[20 marks]</b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "customer_rental = str(\"SELECT * FROM customer c\"\n",
    "                      + \" JOIN payment p\"\n",
    "                      + \" ON c.customer_id=p.customer_id\"\n",
    "                      + \" RIGHT JOIN rental r\"\n",
    "                      + \" ON p.rental_id=r.rental_id\"\n",
    "                      + \" JOIN inventory i\"\n",
    "                      + \" ON i.inventory_id=r.inventory_id\"\n",
    "                      + \" JOIN film f\"\n",
    "                      + \" ON i.film_id=f.film_id\"\n",
    "                      + \" JOIN film_category fc\"\n",
    "                      + \" ON fc.film_id=f.film_id\"\n",
    "                      + \" JOIN category\"\n",
    "                      + \" ON category.category_id=fc.category_id;\"\n",
    "                      )\n",
    "\n",
    "customer_country = str(\"SELECT * FROM customer c\"\n",
    "                       + \" JOIN address a\"\n",
    "                       + \" ON c.address_id=a.address_id\"\n",
    "                       + \" JOIN city\"\n",
    "                       + \" ON city.city_id=a.city_id\"\n",
    "                       + \" JOIN country\"\n",
    "                       + \" ON country.country_id=city.country_id;\")\n",
    "\n",
    "film_actor = str(\"SELECT * FROM film f\"\n",
    "                 + \" JOIN film_actor fa\"\n",
    "                 + \" ON fa.film_id=f.film_id\"\n",
    "                 + \" JOIN actor a\"\n",
    "                 + \" ON a.actor_id=fa.actor_id;\"\n",
    "                 )\n",
    "\n",
    "df_customer_rental = execute_sql(customer_rental)\n",
    "df_customer_country = execute_sql(customer_country)\n",
    "df_film_actor = execute_sql(film_actor)\n",
    "\n",
    "df_film_actor.to_csv(\"film_actor.csv\")\n",
    "df_customer_rental.to_csv(\"customer_rental.csv\")\n",
    "df_customer_country.to_csv(\"customer_country.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customer_country=df_customer_country.loc[:,~df_customer_country.columns.duplicated()]\n",
    "df_customer_country = df_customer_country[[\"customer_id\",\"address_id\",\"active\",\"city_id\",\"country_id\",\"country\"]]\n",
    "\n",
    "df_customer_rental=df_customer_rental.loc[:,~df_customer_rental.columns.duplicated()]\n",
    "df_customer_rental = df_customer_rental[[\"customer_id\",\"store_id\",\"payment_id\",\"rental_id\",\"amount\",\"inventory_id\",\"film_id\",\"rental_duration\",\"rental_rate\",\"length\",\"replacement_cost\",\"rating\",\"special_features\",\"fulltext\",\"category_id\"]]\n",
    "\n",
    "df_film_actor=df_film_actor.loc[:,~df_film_actor.columns.duplicated()]\n",
    "df_film_actor[\"actor_name\"]=df_film_actor.first_name.map(str)+\" \"+df_film_actor.last_name\n",
    "df_film_actor=df_film_actor[[\"film_id\",\"actor_id\",\"actor_name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customer_country     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customer_rental\n",
    "\n",
    "df_customer_rental_country = df_customer_rental.merge(df_customer_country, on='customer_id', how='inner')\n",
    "df_customer_rental_country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filmID_list = []\n",
    "actor_list = []\n",
    "\n",
    "for ele in df_film_actor.groupby(df_film_actor['film_id']):\n",
    "    filmID_list.append(ele[1]['film_id'].values[0])\n",
    "    actor_list.append(list(ele[1]['actor_id']))\n",
    "\n",
    "film_actors = {'film_id': filmID_list, 'actors_id_list': actor_list}\n",
    "\n",
    "df_film_actor = pd.DataFrame(film_actors)\n",
    "df_film_actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_customer_rental.merge(df_film_actor, on='film_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.to_csv('df_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section C - Machine Learning (55 Marks)\n",
    "<span style='color:purple;'><b>Note:</b> We have provided the .csv outputs for the files to use in these questions if you are working on the assignment at home. Please note if any of these questions refer to those csvs and not the data from Section B in your submitted assignment, you will receive no marks for Section B.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TEMPORARY LOADING OF DATAFRAMES (IF WORKING FROM HOME)\n",
    "## Import csv files for home development here as necessary. \n",
    "df_actor = pd.read_csv(\"data/dvd_rental/actor.csv\")\n",
    "df_address = pd.read_csv(\"data/dvd_rental/address.csv\")\n",
    "df_category = pd.read_csv(\"data/dvd_rental/category.csv\")\n",
    "df_city = pd.read_csv(\"data/dvd_rental/city.csv\")\n",
    "df_country = pd.read_csv(\"data/dvd_rental/country.csv\")\n",
    "df_film = pd.read_csv(\"data/dvd_rental/film.csv\")\n",
    "df_film_actor = pd.read_csv(\"data/dvd_rental/film_actor.csv\")\n",
    "df_film_category = pd.read_csv(\"data/dvd_rental/film_category.csv\")\n",
    "df_inventory = pd.read_csv(\"data/dvd_rental/inventory.csv\")\n",
    "df_language = pd.read_csv(\"data/dvd_rental/language.csv\")\n",
    "df_payment = pd.read_csv(\"data/dvd_rental/payment.csv\")\n",
    "df_rental = pd.read_csv(\"data/dvd_rental/rental.csv\")\n",
    "df_staff = pd.read_csv(\"data/dvd_rental/staff.csv\")\n",
    "df_store = pd.read_csv(\"data/dvd_rental/store.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading & Minor Cleanup Of DataFrame\n",
    "df_cleaned = pd.read_csv(\"df_cleaned.csv\")\n",
    "df_cleaned = df_cleaned.drop([\"Unnamed: 0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_combinations(dataframe, dependent_variable):\n",
    "    '''Helper function for producing all possible combinations of independent variables \n",
    "       based on the given dataframe & the dependent_variable\n",
    "       @param:dataframe - The primary DataFrame in which your data resides.\n",
    "       @return:output - A list of list which has all possible combinations.'''\n",
    "    output = []\n",
    "    independent_variables = []\n",
    "    for var in dataframe.columns:\n",
    "        if var != dependent_variable:\n",
    "            independent_variables.append(var)\n",
    "    for i in range(len(independent_variables)):\n",
    "        for combination in list(combinations(independent_variables, i + 1)):\n",
    "            output.append(combination)\n",
    "    return output "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 - Clustering (25 Marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.1 - Clustering Short Answers (8 Marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Can a Decision Tree be used to perform clustering? If so, explain how. If not, provide a counterexample showing how it is not suitable for the function.\n",
    "<span style= 'float: right;'><b>[4 marks]</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:blue\"> Your answer here: </span>\n",
    "- For a given dataset,decision trees can be used to perform only classification,not clustering [(Both are similar,but different)](https://techdifferences.com/difference-between-classification-and-clustering.html) .Decision Trees are a form of Supervised learning and they classify instances based on a known/predefined labels.Decision Trees will use Heuristics(attribute selection measures) such as Information Gain,Gain Ratio or Gini index to decide the decision nodes of the tree.\n",
    "- Counter - Example:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Will a K-means Clustering Algorithm generate the same results each time? Provide examples on how this may or may not be the case.\n",
    "<span style= 'float: right;'><b>[4 marks]</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:blue\"> Your answer here: </span>\n",
    "\n",
    "(Assumed that the centroids are randomly assigned and the number of the centroids are the same each time)\n",
    "\n",
    "The results are usually different. But, it depends on the data and the centroids number. For example, if the data has obvious clusters, and the number of centroids are equal to its clusters. K-means Clustering Algorithm will generate the same result each time no matter where the initial centroids are. For other kinds of data, the result usually depends on the initial position of the centroids."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.2 - K-Means Clustering Implementation (17 Marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering helps visualise a dataset based on attributes considered important to the data scientist and/or reader.  From the dataset acquired after completing **Section - B**, implement a `K-Means clustering algorithm` to help you cluster the dataset of customers on the basis of the movies they have rented from the DVD rental stores. Various attributes related to the movies such `rating`, `year`, `rental_rate` and `year` may be useful for this exercise. Another interesting attribute that you can look at is the `fulltext` of the movie. In terms of the customer details, you can look at which movies a customer has rented, and the total number of movies rented by a customer. After you've prepared your learning model, plot a **visualization** showing the different clusters. If you have used more than 2 features for your clustering, you are still expected to provide a visualization by reducing the dimensions into a 2D graph.\n",
    "\n",
    "It's upto you to decide how many clusters you would like to incorporate in your model. You are expected to justify all aspects of your implementation including the reasoning behind the choice of **the number of clusters** and **number of iterations** in your model. \n",
    "\n",
    "<span style='color:red;'><b>Note:</b> You are only allowed to use packages that are within the Anaconda distribution.</span>\n",
    "<span style= 'float: right;'><b>[15 marks total: 10 marks model, 5 marks justification & commentary]</b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Change Category data \"Rating\" from String to Numeric\n",
    "df_cleaned['rating'] = df_cleaned['rating'].astype(\"category\").cat.codes\n",
    "\n",
    "# Principal Component Analysis - \n",
    "pca = PCA(n_components=2)\n",
    "df_X = df_cleaned[['rental_duration', 'rental_rate', 'length', 'replacement_cost', 'rating', 'category_id']]\n",
    "df_X = df_X.dropna()\n",
    "pca.fit(df_X)\n",
    "transform = pca.transform(df_X)\n",
    "\n",
    "# Finding the best number of clusters (k) for KMeans\n",
    "sse = []\n",
    "for i in range(1, 13):\n",
    "    KM = KMeans(n_clusters=i)\n",
    "    KM.fit(transform)\n",
    "    sse.append(KM.inertia_)\n",
    "plt.plot(range(1, 13), sse)\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"Sum of Squared Error\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# As shows from above, the optimal value of K is 3\n",
    "km = KMeans(n_clusters=3)\n",
    "km.fit(transform)\n",
    "predicted_clusters = km.predict(transform)\n",
    "centers = km.cluster_centers_\n",
    "\n",
    "markers = ['o', 'x', 's']\n",
    "colors = ['purple', 'b', 'yellow']\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(transform[:, 0], transform[:, 1], c=predicted_clusters, s=7)\n",
    "for ind in range(len(markers)):\n",
    "    plt.scatter(centers[ind, 0], centers[ind, 1], c=colors[ind], s=100, marker=markers[ind])\n",
    "plt.title('Result of k-means Clustering', fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "df_X['cluster'] = predicted_clusters\n",
    "cluster0 = df_X[df_X['cluster'] == 0]\n",
    "cluster1 = df_X[df_X['cluster'] == 1]\n",
    "cluster2 = df_X[df_X['cluster'] == 2]\n",
    "\n",
    "print(cluster0.describe())\n",
    "print(cluster1.describe())\n",
    "print(cluster2.describe())\n",
    "\n",
    "# compare the rating in accordance  within the cluster Visually;\n",
    "# the number of datapoint in each cluster .\n",
    "# Check category_id counts in each cluster & try to distinguish them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "colors = ['purple', 'r', 'yellow']\n",
    "for c in range(3):\n",
    "    rating_count=df_X[df_X['cluster'] == c].groupby(\"rating\").count().amount\n",
    "    plt.bar(rating_count.index,rating_count.values,alpha=(c+1)*0.15,color=colors[c]) \n",
    "plt.show()     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:blue\"> Your justifications & commentary here: </span>\n",
    "- The k value was decided based on using elbow method to find the optimal k clusters such that it has a minimised misrepresentation of cluster.The Point at which there is a significant change in Sum of squared error resulting in a notable,sharp  dip in the plot , is the elbow point for the given data.\n",
    "- Based on the elbow method's result ,the appropriate k value is used for clustering.\n",
    "\n",
    "- The number of data points in cluster 0 has a notable difference when compared to the other clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What do your resulting clusters represent?  Explain the distinguishing characteristics of each cluster. \n",
    "<span style= 'float: right;'><b>[2 marks]</b></span>\n",
    "The resulting cluster represent "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:blue\"> Your answer here: </span>\n",
    "\n",
    "**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 - Classification (30 Marks)\n",
    "\n",
    "The rental company has decided that they want to use simple machine learning to allocate price tags to their movies. The tags are as follows:\n",
    "\n",
    "\n",
    "|  **Classification**      |  **Requirements**        |\n",
    "|--------------------------|------------------------- |\n",
    "|  Cheap                   |  Rental Rate is 0.99   |\n",
    "|  Moderate                |  Rental Rate is 2.99   |\n",
    "|  Expensive               |  Rental Rate is 4.99  |\n",
    "\n",
    "\n",
    "**Your task is to implement a `Classification Algorithm` (such as K-Nearest Neighbours) that can predict the `Price Label` of a movie**. You are required to perform the following tasks:\n",
    "\n",
    "1. Create useable dataset/s by manually determining the 'truth values' for existing data (where the rating is within the classification system defined above)\n",
    "2. Implement an algorithm that can predict the classification as per the above classifications.\n",
    "3. Perform independent testing of the model and provide statistical metrics outlining the performance of your model. Splitting the dataset into testing and training subsets will assist with this.\n",
    "\n",
    "You are welcome to use any features within the dataset, except the `Rental Rate` of the film. Various attributes relating to a movie in the tables `rating`, `movie`, `film_actor`, `actor` and `film_category` can be helpful while making the algorithm. If required, you can also look to make new **compound attributes** that may be helpful in increasing the accuracy of your model.\n",
    "You are expected to justify all aspects of your answer including the features used, the metrics provided and validation system employed. Provide commentary on the strengths and potential pitfalls of the model.\n",
    "\n",
    "<span style='color:red;'><b>Note:</b> You are only allowed to use packages that are within the Anaconda distribution. This means packages such as Keras, Tensorflow etc are not available for use.</span> \n",
    "<span style= 'float: right;'><b>[25 marks total: 18 marks model, 7 marks justification & commentary]</b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   category_id  rental_rate  rating  length  rental_duration  \\\n",
      "0           11            4       4     153                6   \n",
      "1            6            0       2     130                5   \n",
      "2           13            4       2     138                3   \n",
      "3            4            2       0     100                5   \n",
      "4           10            4       4     165                6   \n",
      "\n",
      "   replacement_cost  amount  film_rented_count  \n",
      "0                19       6                 16  \n",
      "1                15       2                 17  \n",
      "2                 9       6                 24  \n",
      "3                11       4                 26  \n",
      "4                16       5                 30  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_id</th>\n",
       "      <th>rental_rate</th>\n",
       "      <th>rating</th>\n",
       "      <th>length</th>\n",
       "      <th>rental_duration</th>\n",
       "      <th>replacement_cost</th>\n",
       "      <th>film_rented_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>153</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>138</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>165</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>161</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>119</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>82</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>114</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>178</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>180</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>85</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>132</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>178</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>156</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>86</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>122</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>171</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>175</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>87</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>140</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>119</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>132</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>139</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>177</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>104</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>180</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>88</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>146</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>71</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>153</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>94</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>72</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>133</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>106</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>119</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>955 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     category_id  rental_rate  rating  length  rental_duration  \\\n",
       "0             11            4       4     153                6   \n",
       "1              6            0       2     130                5   \n",
       "2             13            4       2     138                3   \n",
       "3              4            2       0     100                5   \n",
       "4             10            4       4     165                6   \n",
       "5             14            0       0      86                3   \n",
       "6              9            4       4     161                7   \n",
       "7             11            4       2      85                4   \n",
       "8             14            2       3     119                4   \n",
       "9              8            4       2      92                7   \n",
       "10            11            2       4      82                4   \n",
       "11            16            0       2     114                5   \n",
       "12             9            0       3     178                4   \n",
       "13             9            2       1     180                6   \n",
       "14            14            2       4      85                3   \n",
       "15             6            0       3     132                7   \n",
       "16             9            0       3     178                3   \n",
       "17            12            4       1      47                5   \n",
       "18            15            0       3     156                5   \n",
       "19             6            0       2      86                6   \n",
       "20             5            4       4      58                5   \n",
       "21            13            0       1     122                4   \n",
       "22             8            2       1     130                5   \n",
       "23             5            0       2     171                4   \n",
       "24             5            2       3     144                3   \n",
       "25             7            4       0     175                5   \n",
       "26             4            0       1      99                7   \n",
       "27            16            4       0      74                3   \n",
       "28             8            4       1     144                3   \n",
       "29             1            4       4      87                6   \n",
       "..           ...          ...     ...     ...              ...   \n",
       "925           16            4       0      81                7   \n",
       "926           15            4       4     140                5   \n",
       "927            8            0       1     119                5   \n",
       "928            5            0       0     115                6   \n",
       "929           11            0       1      51                3   \n",
       "930           16            4       0     139                5   \n",
       "931            9            0       2      99                3   \n",
       "932            5            4       3     132                7   \n",
       "933            8            4       1      52                4   \n",
       "934           16            2       1      61                5   \n",
       "935           13            0       3     139                4   \n",
       "936           15            2       2     177                5   \n",
       "937            4            2       2      65                3   \n",
       "938            1            0       2     104                6   \n",
       "939            9            2       3     180                6   \n",
       "940           11            0       0     158                6   \n",
       "941           12            4       4      88                5   \n",
       "942            6            2       1     106                5   \n",
       "943           11            0       1     179                7   \n",
       "944           13            2       1     146                7   \n",
       "945           11            4       4      71                3   \n",
       "946            6            0       0     171                5   \n",
       "947           16            2       3     153                6   \n",
       "948            3            2       2      94                6   \n",
       "949            6            2       4      72                7   \n",
       "950            5            0       3     133                5   \n",
       "951            3            4       2      53                6   \n",
       "952           16            4       1      76                6   \n",
       "953           10            4       2     106                7   \n",
       "954           13            4       4     119                6   \n",
       "\n",
       "     replacement_cost  film_rented_count  \n",
       "0                  19                 16  \n",
       "1                  15                 17  \n",
       "2                   9                 24  \n",
       "3                  11                 26  \n",
       "4                  16                 30  \n",
       "5                  15                 22  \n",
       "6                  22                 23  \n",
       "7                  24                 24  \n",
       "8                  12                 13  \n",
       "9                   9                 13  \n",
       "10                 27                  9  \n",
       "11                 27                 10  \n",
       "12                 14                 25  \n",
       "13                 23                 14  \n",
       "14                 21                 21  \n",
       "15                 28                 16  \n",
       "16                 27                 33  \n",
       "17                 21                 17  \n",
       "18                 14                 16  \n",
       "19                 20                 23  \n",
       "20                 12                 28  \n",
       "21                 14                 19  \n",
       "22                  9                 24  \n",
       "23                 27                 20  \n",
       "24                 24                 23  \n",
       "25                 28                 22  \n",
       "26                 29                 19  \n",
       "27                 25                 17  \n",
       "28                 14                 14  \n",
       "29                 12                 15  \n",
       "..                ...                ...  \n",
       "925                29                  6  \n",
       "926                26                  6  \n",
       "927                17                  6  \n",
       "928                25                  7  \n",
       "929                26                  6  \n",
       "930                13                  5  \n",
       "931                11                  8  \n",
       "932                10                 11  \n",
       "933                19                  9  \n",
       "934                19                  6  \n",
       "935                29                  8  \n",
       "936                28                 11  \n",
       "937                18                 14  \n",
       "938                22                 12  \n",
       "939                26                  4  \n",
       "940                13                 13  \n",
       "941                11                  6  \n",
       "942                23                  6  \n",
       "943                22                  6  \n",
       "944                26                  8  \n",
       "945                26                  4  \n",
       "946                13                  7  \n",
       "947                21                  7  \n",
       "948                14                  5  \n",
       "949                15                  4  \n",
       "950                23                  5  \n",
       "951                17                  6  \n",
       "952                13                  6  \n",
       "953                26                  5  \n",
       "954                11                  6  \n",
       "\n",
       "[955 rows x 7 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rental duration for any particular film is the constant \n",
    "# We might need to Convert special_features & actos_id_list to dummy variables\n",
    "\n",
    "# Loading appropriate data\n",
    "df_classification_original = df_cleaned[[\"category_id\",\"film_id\", \"rental_rate\", \"rating\", \"length\", \"rental_duration\", \"replacement_cost\", \"amount\"]]\n",
    "\n",
    "# Filling Nas in amounts with the average of amounts\n",
    "df_amount_mean = df_classification_original.groupby(\"film_id\").agg({\"amount\": \"mean\"})\n",
    "df_classification = df_classification_original.set_index(\"film_id\")\n",
    "df_classification.amount = df_classification.amount.fillna(df_amount_mean.amount)\n",
    "df_classification.reset_index()\n",
    "\n",
    "\n",
    "# Converting categorical data(rating)\n",
    "le = LabelEncoder()\n",
    "df_classification.rating = le.fit_transform(df_classification.rating)\n",
    "\n",
    "# Replacing amounts with it's mean values & joining dataframes based on film_id\n",
    "df_amount_mean = df_classification.groupby(\"film_id\").agg({\"amount\": \"mean\"})\n",
    "\n",
    "\n",
    "film_frq = df_classification.groupby(by=\"film_id\")['category_id'].count()\n",
    "# df_classification[\"film_frequency\"]=df_classification.drop([\"amount\"], axis=1)\n",
    "\n",
    "\n",
    "df_classification = df_classification.drop([\"amount\"], axis=1).drop_duplicates()\n",
    "df_classification = df_classification.join(df_amount_mean, on=\"film_id\")\n",
    "df_classification['film_rented_count'] = film_frq\n",
    "df_classification = df_classification.reset_index().drop([\"film_id\"], axis=1)\n",
    "\n",
    "df_classification = df_classification.astype(np.int64)  # For KNN function data should be in integers\n",
    "print(df_classification.head())\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(df_classification.values, i) for i in range(df_classification.shape[1])]\n",
    "vif[\"Features\"] = df_classification.columns\n",
    "vif\n",
    "\n",
    "\n",
    "df_classification = df_classification.drop('amount',axis=1)\n",
    "df_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_classification(df_classification,features):\n",
    "    '''Based on given features,a KNN classification will be done for all possible combinations.\n",
    "       @param df_classification: The input dataframe whcih contans the dependent variable and the other features\n",
    "       @param features: A list which contains features which should be recognised by the classification\n",
    "       @result df_scores: A dataframe which contains all model's Accuracy Scores '''\n",
    "\n",
    "    #Initialisations\n",
    "    kvalues=int(np.sqrt(df_classification.shape[0]))\n",
    "    # Making sure k values is odd.\n",
    "    kn = KNeighborsClassifier(n_neighbors=(kvalues if kvalues%2!=0 else kvalues+1))\n",
    "    all_combinations = feature_combinations(df_classification[features], \"rental_rate\")\n",
    "    df_scores = pd.DataFrame()\n",
    "\n",
    "    # C\n",
    "    for combination in all_combinations:\n",
    "        x_train, x_test, y_train, y_test = train_test_split(df_classification[list(combination)],\n",
    "                                                        df_classification.rental_rate, test_size=0.33)\n",
    "        fit = kn.fit(x_train, y_train)\n",
    "        df_scores[str(list(combination))] = [np.mean(cross_val_score(kn, x_test, y_test, cv=10, scoring='accuracy'))]\n",
    "        if (len(combination) > 1):\n",
    "            for i in range(len(combination) - 1):\n",
    "            # trying a combination in which dimensionality of the features are reduced using PCA.            \n",
    "                pca = PCA(n_components=i + 1)\n",
    "                data_x = pca.fit_transform(df_classification[list(combination)])\n",
    "                x_train, x_test, y_train, y_test = train_test_split(data_x, df_classification.rental_rate, test_size=0.33)\n",
    "                fit = kn.fit(x_train, y_train)\n",
    "                df_scores[\"PCA_\" + str(i + 1) + str(list(combination))] = [np.mean(cross_val_score(kn, data_x, df_classification.rental_rate, cv=10, scoring='accuracy'))]\n",
    "\n",
    "    df_scores.index = [\"Scores\"]\n",
    "    df_scores = df_scores.T\n",
    "    df_scores = df_scores.sort_values(by=[\"Scores\"], ascending=False)\n",
    "\n",
    "    # # https://stackoverflow.com/questions/19124601/pretty-print-an-entire-pandas-series-dataframe\n",
    "    from IPython.display import display\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "        display(df_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>['category_id']</th>\n",
       "      <td>0.360340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['category_id', 'rating']</th>\n",
       "      <td>0.358636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['rating']</th>\n",
       "      <td>0.332231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA_1['category_id', 'rating']</th>\n",
       "      <td>0.328733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Scores\n",
       "['category_id']                 0.360340\n",
       "['category_id', 'rating']       0.358636\n",
       "['rating']                      0.332231\n",
       "PCA_1['category_id', 'rating']  0.328733"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "knn_classification(df_classification,[\"category_id\", \"rental_rate\", \"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Support Vector Machines\n",
    "svmo = svm.SVC(kernel='linear') \n",
    "all_combinations=feature_combinations(df_classification,\"rental_rate\")\n",
    "df_scores=pd.DataFrame()\n",
    "\n",
    "for combination in all_combinations:\n",
    "    x_train,x_test,y_train,y_test=train_test_split(df_classification[list(combination)],df_classification.rental_rate,test_size=0.2)\n",
    "    svmo = svm.SVC(kernel='linear') # Linear Kernel\n",
    "    svmo.fit(x_train, y_train)\n",
    "    y_pred = svmo.predict(x_test)\n",
    "    df_scores[str(list(combination))]=[metrics.accuracy_score(y_test, y_pred)]\n",
    "            \n",
    "df_scores.index=[\"Scores\"]\n",
    "df_scores=df_scores.T\n",
    "df_scores=df_scores[df_scores.Scores>0.9].sort_values(by=[\"Scores\"],ascending=False)\n",
    "\n",
    "# # https://stackoverflow.com/questions/19124601/pretty-print-an-entire-pandas-series-dataframe\n",
    "from IPython.display import display\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None): \n",
    "    display(df_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:blue\"> Your justifications & commentary here: </span>\n",
    "\n",
    "**Firstly, we create the K-Nearest Neighbours algorithmns with the category_id\",\"film_id\", \"rental_rate\", \"rating\", \"length\", \"rental_duration\", \"replacement_cost\", \"amount\" and got the perfect score of about 0.97. The results show that we are overfitting the data and determined that some independent variables have multicollinearity to one another. So, we tried to find out by using the variance inflation factor method (VIF) which indicates the variables are not completely independent to each other if the result is over 10. We also find out that the VIF of feature 'amount' is over 27 which shows a very serious multicollinearity. So, we re-ran K-Nearest Neighbours algorithmns without the feature 'amount' and it got the score of 0.4 which is our final prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Would you be able to get a better result, if you had used Clustering as a pre-processing step before Classfication? Justify your answer. \n",
    "<span style= 'float: right;'><b>[5 marks]</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:blue\"> Your answer here: </span>\n",
    "\n",
    "** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section D - Decision Trees (10 Marks)\n",
    "\n",
    "The following is a small synthetic data set about the weather conditions.  We are\n",
    "going to try and use decision trees to predict whether it will rain or not on the given day.\n",
    "\n",
    "\n",
    "|Temperature| Cloudy| UV Index| Humidity| Rain\n",
    "|---:|--:|--:|--:|--:|\n",
    "|25|No| Low| Low| No \n",
    "|29|No| Low| High| No\n",
    "|26|No| Low| Medium| No\n",
    "|26|No| Medium| Medium| No\n",
    "|27|No| Medium| High| No\n",
    "|28|No| High | High| No\n",
    "|25|No| High |Low| No\n",
    "|29|Yes| Low |Low| Yes\n",
    "|28|No| Medium| High| Yes\n",
    "|28|Yes| Medium| High| Yes\n",
    "|26|No| Low |Low| Yes\n",
    "|27|Yes| Low |High| Yes\n",
    "\n",
    "**Note:**\n",
    "* You can treat temperature as a continuous variable and split it on a range of values (to convert it to a categorical variable, for example).\n",
    "* Attribute selection in the tree uses information gain.\n",
    "* You can use LaTeX and/or markdown to format your equations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rain = pd.read_csv(\"rain.csv\")\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn import tree\n",
    "\n",
    "replacement_items = {\"No\": 0, \"Yes\": 1, \"Low\": 1, \"Medium\": 2, \"High\": 3}\n",
    "df_rain = df_rain.replace(replacement_items)\n",
    "df_rain_X = df_rain.drop(labels=['Rain'], axis=1)\n",
    "df_rain_y = df_rain['Rain']\n",
    "dt = DecisionTreeClassifier(criterion=\"entropy\", presort=True)\n",
    "dt.fit(df_rain_X, df_rain_y)\n",
    "dotf = export_graphviz(dt, out_file='decision_tree.dot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. What is the initial entropy of Cloudy?\n",
    "\n",
    "<span style= 'float: right;'><b>[3 marks]</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<span style=\"color:blue\">\n",
    "    \n",
    "#### By using the formula of entrophy which is ∑ xЄX log, The initial entropy of Cloudy will be approximately 0.8112\n",
    "$\\sum_{k=1}$\n",
    "\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Which attribute would the decision-tree building algorithm choose at the root of the tree?\n",
    "\n",
    "<span style= 'float: right;'><b>[3 marks]</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">\n",
    "    \n",
    "#### Cloudy would be the best attribute for choosing the decision tree building.\n",
    "\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Calculate and specify the information gain of the attribute you chose to split on in the previous question\n",
    "\n",
    "<span style= 'float: right;'><b>[4 marks]</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">\n",
    "    \n",
    "#### YOUR ANSWER HERE\n",
    "\n",
    "\n",
    "</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
